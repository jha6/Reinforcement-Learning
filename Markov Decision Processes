Assignment: Describe Three MDPs

My Answer: 
Examples of the Markov Decision Processes:
A.	An Example of MDP can be a Pong game, where the goal is to never miss the ball, i.e., position the paddle/board to touch the incoming ball. The states would be the position of the ball and the board. The actions could be moving the board to the top and down positions. The reward could be +1 every time the board touches the ball to encourage the agent to touch the ball, and -100 if the board misses the ball so that it knows not to miss.
B.	An Example of MDP can be a Robot Vacuum, where the goal is to clean the room in minimum steps. The states would be the readings from the scanner and GPS such as present location, navigation/direction, battery level, speed, camera, and laser beam. The actions could be moving forward, left, right, and going to the charging dock station in case of a low battery level. The reward could be -1 for every step it takes so that the agent learns to do the cleaning task in the minimum possible steps i.e., do it quickly. Also, the reward could be -100 if it shuts off in between the task (if it didn’t go to the charging dock station) so that it doesn’t skip this task, if applicable.
C.	An Example of MDP can be a game, where the player’s goal is to collect maximum rewards and avoid enemies in the path. The states would be the position of the rewards and the enemy. The actions could be moving the player to the left, right, forward, or jump. The reward could be +1 every time it touches the reward to encourage the agent to touch/collect the reward, and -100 if it touches the enemy so that it knows to avoid doing it.
